name: dbt CI

on:
  pull_request:
    branches:
      - main
    paths:
      - 'dbt/**'
      - 'Makefile'
      - 'scripts/dbt-wrapper.sh'
      - '.github/workflows/dbt.yml'

jobs:
  run-dbt:
    name: Validate dbt project
    runs-on: ubuntu-latest
    env:
      CI_USE_SEEDS: 'true'
      DBT_PROFILES_DIR: ${{ runner.temp }}/dbt-profiles
      DBT_TARGET: ci
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: ads_reporting
          POSTGRES_USER: db_user
          POSTGRES_PASSWORD: db_password
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U db_user -d ads_reporting" --health-interval 10s --health-timeout 5s --health-retries 5
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dbt dependencies
        run: |
          python -m pip install --upgrade pip
          # Pin the adapter to the 1.10-compatible build so it matches dbt-core.
          python -m pip install "dbt-core==1.10.13" "dbt-postgres==1.10.0b1"

      - name: Prepare dbt profile
        run: |
          mkdir -p "$DBT_PROFILES_DIR"
          cp dbt/profiles-ci.yml "$DBT_PROFILES_DIR/profiles.yml"

      - name: Wait for Postgres
        run: |
          for _ in 1 2 3 4 5 6 7 8 9 10; do
            if pg_isready -h localhost -p 5432 -U db_user -d ads_reporting; then
              exit 0
            fi
            sleep 3
          done
          echo "Postgres failed to become ready" >&2
          exit 1

      - name: Install dbt packages
        run: make dbt-deps DBT="python -m dbt" DBT_PROJECT_DIR=dbt

      - name: Seed reference data
        run: python -m dbt seed --project-dir dbt

      - name: Reset dbt target directory
        run: |
          rm -rf dbt/target
          mkdir -p dbt/target

      - name: Run staging models
        run: python -m dbt run --project-dir dbt --select staging

      - name: Generate dbt docs artifacts
        if: ${{ always() }}
        run: |
          if [ -f dbt/target/manifest.json ]; then
            python -m dbt docs generate --project-dir dbt --profiles-dir $HOME/.dbt
          else
            echo "manifest.json missing; skipping docs generation"
          fi

      - name: Summarize dbt run
        if: ${{ always() }}
        run: |
          python - <<'PY'
          import json
          import os
          from pathlib import Path

          target_dir = Path("dbt/target")
          run_results_path = target_dir / "run_results.json"
          summary_path = Path(os.environ["GITHUB_STEP_SUMMARY"])

          if run_results_path.exists():
              data = json.loads(run_results_path.read_text())
              results = data.get("results", [])
              total_models = len(results)
              failed_models = sum(1 for result in results if result.get("status") != "success")
              details = [
                  "## dbt run summary",
                  "",
                  f"- Models run: {total_models}",
                  f"- Models failed: {failed_models}",
              ]
          else:
              details = [
                  "## dbt run summary",
                  "",
                  "- Run results not available; dbt may have failed before writing artifacts.",
              ]

          with summary_path.open("a", encoding="utf-8") as summary_file:
              summary_file.write("\n".join(details) + "\n")
          PY

      - name: Ensure dbt target directory exists
        if: ${{ always() }}
        run: mkdir -p dbt/target

      - name: Build artifact inventory
        if: ${{ always() }}
        run: |
          python - <<'PY'
          import json
          from datetime import datetime, timezone
          from pathlib import Path

          target_dir = Path("dbt/target")
          run_results_path = target_dir / "run_results.json"
          manifest_path = target_dir / "manifest.json"
          inventory_path = target_dir / "artifact-inventory.json"

          inventory = {
              "generated_at": None,
              "project_name": None,
              "adapter_type": None,
              "models": [],
              "tests": [],
          }

          if run_results_path.exists():
              try:
                  run_results = json.loads(run_results_path.read_text())
              except json.JSONDecodeError:
                  run_results = {}
              metadata = run_results.get("metadata", {})
              inventory.update(
                  {
                      "generated_at": run_results.get("generated_at"),
                      "project_name": metadata.get("project_id"),
                      "adapter_type": metadata.get("adapter_type"),
                  }
              )
              results = run_results.get("results", [])
          else:
              results = []

          manifest_nodes = {}
          if manifest_path.exists():
              try:
                  manifest_nodes = json.loads(manifest_path.read_text()).get("nodes", {})
              except json.JSONDecodeError:
                  manifest_nodes = {}

          for result in results:
              unique_id = result.get("unique_id", "")
              node = manifest_nodes.get(unique_id, {})
              entry = {
                  "name": node.get("name") or unique_id.split(".")[-1],
                  "unique_id": unique_id,
                  "status": result.get("status"),
                  "execution_time": result.get("execution_time"),
              }

              resource_type = node.get("resource_type") or unique_id.split(".")[0]
              if resource_type == "model":
                  entry.update(
                      {
                          "materialization": (node.get("config") or {}).get("materialized"),
                          "path": node.get("path"),
                      }
                  )
                  inventory["models"].append(entry)
              elif resource_type == "test":
                  test_metadata = node.get("test_metadata") or {}
                  entry.update(
                      {
                          "test_type": test_metadata.get("name"),
                          "severity": (node.get("config") or {}).get("severity"),
                          "failures": result.get("failures"),
                          "message": result.get("message"),
                      }
                  )
                  inventory["tests"].append(entry)

          if inventory["generated_at"] is None:
              inventory["generated_at"] = datetime.now(timezone.utc).isoformat()

          inventory_path.write_text(json.dumps(inventory, indent=2), encoding="utf-8")
          print(json.dumps(inventory, indent=2))
          PY

      - name: Upload dbt artifacts
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: dbt-staging-artifacts
          path: |
            dbt/target/artifact-inventory.json
            dbt/target/catalog.json
            dbt/target/manifest.json
            dbt/target/run_results.json
            dbt/target/graph.gpickle
            dbt/target/graph_summary.json
            dbt/target/partial_parse.msgpack
            dbt/target/semantic_manifest.json
            dbt/target/compiled
            dbt/target/run
            dbt/logs
          if-no-files-found: warn
